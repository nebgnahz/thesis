\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Compute Resource Adaptation}
\label{cha:comp-reso-adapt}

In this chapter, we focus on swarm applications with computation-heavy tasks,
such as machine learning (ML) inference. To create an engaging user experience,
these applications need to offer bounded response times (e.g., 100 ms or
sub-second). However, end devices are often not powerful enough to run an
algorithm as is. While applications can offload computation to other resources
such as the edge or the cloud, swarm platforms have a large discrepancy of
computing capabilities. In addition, the edge/cloud faces the challenge of
unpredictable network delays and service overload. To meet the response time
requirement, we propose to adapt computation to each platform.

The ability to adapt comes from the availability of many options to for the same
task: different algorithms or different parameters for the same algorithm. These
options result in different processing times and application accuracy. If we can
build a performance model that characterizes the impact of each option, the
application can choose the right algorithm/parameter adaptively depending on the
available compute power and meet the deadline.

Building this performance model for compute resource adaptation is
challenging. Unlike the profiling discussed in \autoref{cha:netw-reso-adapt},
exhaustive profiling is not viable due to two issues: $(i)$ we are facing
algorithms with more parameters that form a much larger combinatorial space;
$(ii)$ because processing times vary across devices, we need to profile for each
swarm device, even those that are not available at development time but will be
used at deployment.

This chapter is step further in refining our profiling techniques. First, we
address the issue with a large parameter space by employing Bayesian
Optimization (BO). We demonstrate that BO can reduce the number of samples we
need by 50$\times$ compared to an exhaustive approach. With the same search
budget, BO finds better Pareto-optimal configurations than random search and
coordinate search. Second, to profile for new devices, we propose to transfer an
existing profile by updating the processing times of Pareto-optimal
configurations. The profile transfer eliminates the need to get all training
data, evaluate the algorithm for all data, and run BO engine.

\input{brt/intro}
\input{brt/motivation}
\input{brt/modeling}
\input{brt/discussions}
\input{brt/conclusion}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
