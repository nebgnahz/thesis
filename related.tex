\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Related Work}
\label{cha:related-work}

In this chapter, we survey related work wide-area streaming systems,

\section{Approximation and Adaptation}
\label{sec:appr-adapt}

Many recent systems have explored the idea of degrading computation fidelity for
responsiveness.  For SQL queries, BlinkDB~\cite{agarwal2013blinkdb} enables
interactive queries over massive data by allowing users to trade-off query
accuracy. For cloud analytics, GRASS~\cite{ananthanarayanan2014grass}, For
real-time computing, MEANTIME~\cite{farrell2016meantime} exploits application
approximation to provide both hard real-time guarantees and energy
efficiency. VideoStorm~\cite{zhang2017live} scales to processing thousands of
video streams in large cluster with a resource scheduler that adapts the
processing quality. They employ techniques such as programming language
support~\cite{sampson2011enerj}, sampling~\cite{garofalakis2001approximate},
sketches~\cite{cormode2011sketch}, and online
aggregation~\cite{hellerstein1997online}. This thesis targets at swarm
applications, an emerging domain with its own unique challenges: constrained
resources and heterogeneous capabilities.

The closest system to our \awstream{} is JetStream~\cite{rabkin2014aggregation},
the first to use degradation to reduce latency for wide-area streaming
analytics. Compared to JetStream, \sysname{} makes five major contributions:
$(1)$~a novel API design to specify degradation in a simple and composable way;
$(2)$~automatic offline profiling to search for Pareto-optimal configurations;
$(3)$~online profiling to address model drift; $(4)$~an improved runtime system
achieving sub-second latency (comparison in \autoref{sec:runtime-adaptation});
$(5)$~support for different resource allocation policies for multiple
applications.

\para{(Adaptive) Video Streaming.} Multimedia streaming protocols
(e.g.,~RTP~\cite{schulzrinne2006rtp}) aim to be fast instead of reliable. While
they can achieve low latency, their accuracy can be poor under congestion.
Recent work has moved towards HTTP-based protocols and focused on designing
adaptation strategy to improve QoE, as in research~\cite{mao2017neural,
  sun2016cs2p, yin2015control} and industry (HLS~\cite{pantos2016http},
DASH~\cite{michalos2012dynamic, sodagar2011mpeg}). These adaptation strategies
are often pull-based: client keeps checking the index file for changes. And
clients have to wait for the next chunk (typically 2-10 seconds). In addition,
as we have shown in \autoref{sec:runtime-adaptation}, their adaptation is a poor
match for analytics that rely on image details (e.g.,~6\% accuracy for PD). In
contrast we propose to learn an adaptation strategy for each application (also
not limited to video analytics); and in our network resource adaptation,
\awstream{}'s runtime is optimized for low latency.

\section{Quality of Service}
\label{sec:quality-service}

Most QoS work~\cite{ferrari1990scheme, shenker1994integrated,
  shenker1995fundamental} in the 1990s focuses on network-layer solutions that
are not widely deployable. \sysname{} adopts an end-host application-layer
approach ready today for WAN. For other application-layer
approaches~\cite{vandalore2001survey}, \sysname{}'s API can incorporate their
techniques, such as encoding the number of layers as a knob to realize the
layered approach in Rejaie et al~\cite{rejaie2000layered}. Fundamentally,
\sysname{} does not provide hard QoS guarantees; instead \sysname{} maximizes
achievable accuracy (application performance) and minimizes latency (system
performance) with respect to bandwidth constraints: a multidimensional
optimization.

\para{SLO-awareness.} MittOS~\cite{hao2017mittos} advocates the return of
\texttt{EBUSY} for IO operations to bound IO requests.

%% TCP, for example, adapts to available bandwidth by controlling the congestion
%% window with AIMD~\cite{jacobson1988congestion}.  Previous work has proposed
%% modifications to TCP for specific contexts. For streaming over TCP, Goel et
%% al.~\cite{goel2008low} proposes adaptive buffer-size tuning. For the cloud,
%% Adaptive TCP~\cite{wu2013adaptive} proposes to modify the congestion control
%% behavior based on flow size for the cloud.

% \para{Scheduling and allocation:} Resource allocations in the cloud is how to
% efficiently allocate tasks.  In the wide area, we face fundamental limit that
% therefore degradation is more effective. For multiple tasks, Existing
% allocations are for resources without considering application trade-offs.
% MediaNet~\cite{hicks2003user} uses both local and online global resource
% scheduling to improve user performance and network utilization, and adapts
% without requiring underlying support for resource
% reservations. VideoStorm~\cite{zhang2017live} primarily focuses on cluster
% resource allocation among video queries. For wide-area, the resource
% allocation is limited. We do not control the capacity; but still we can
% allocate the available bandwidth.

% Performance modeling: CherryPick~\cite{alipourfard2017cherrypick},
% Ernest~\cite{venkataraman2016ernest}.
%% Dolly~\cite{ananthanarayanan2013effective}.
%% \para{Program Synthesis:}

\section{Taming Constrained Resources}
\label{sec:taming-constr-reso}

In this thesis, we have addressed two types of constrained resources: network
resources, i.e. scarce and variable WAN bandwidth, and compute resources,
i.e. heterogeneous swarm devices. We group related work into these two types.

\subsection{Scarce and Variable WAN Bandwidth}
\label{sec:scarce-variable-wan}

Geo-distributed systems need to cope with high latency and limited
bandwidth. While some systems assume the network can prioritize a small amount
of critical data under congestion~\cite{cho2012surviving}, most systems reduce
data sizes in the first place to avoid congestion
(e.g.,~LBFS~\cite{muthitacharoen2001low}). Over the past two years, we have seen
a plethora of geo-distributed analytical
frameworks~\cite{vulimiri2015wananlytics, vulimiri2015global, pu2015low,
  kloudas2015pixida, viswanathan2016clarinet} that incorporate heterogeneous
wide-area bandwidth into query optimization to minimize data movement. While
effective in speeding up analytics, these systems focus on batch tasks such as
MapReduce jobs or SQL queries. Such tasks are often executed infrequently and
without real time constrain. In contrast, \sysname{} processes streams
continuously in real time.

\begin{itemize}
\item Pixida~\cite{kloudas2015pixida} minimizes data movement across inter-DC
  links by solving a traffic minimization problem in data analytics.

\item Iridium~\cite{pu2015low} optimizes data and task placement jointly to
  achieve an overall low latency goal.

\item Clarinet~\cite{viswanathan2016clarinet} incorporate bandwidth information
  into query optimizer to reduce data transfer.

\item Geode~\cite{vulimiri2015global} develops input data movement and join
  algorithm selection strategies to minimize WAN bandwidth usage.

\item WANalytics~\cite{vulimiri2015wananlytics} focuses on batch analytics.

\item SWAG~\cite{hung2015scheduling} coordinates compute task scheduling across
  DCs.

\item \cite{heintz2015towards} discusses the complex trade-offs involved in
  wide-area analytics.

\end{itemize}

\subsection{Heterogeneous Computing Capabilities}
\label{sec:heter-proc-capab}

Prior offloading framework, such as MAUI~\cite{cuervo2010maui},
CloneCloud~\cite{chun2011clonecloud}, Gabriel~\cite{ha2014towards}, and
Tango~\cite{gordon2015accelerating}, runs the same algorithm (with the same
configurations) across different machines: a poor match for the future
heterogeneous mobile-edge-cloud (MEC) environment. \sysname{} explicitly models
performance and select the appropriate algorithm and configuration at runtime.

\para{Low Latency via Redundancy.} The idea of initiating redundant operations
across diverse resources and using the first result which completes has been
explored in many contexts, such as cloud
computing~\cite{ananthanarayanan2013effective}, cloud
service~\cite{dean2013tail}, wide-area network service~\cite{vulimiri2013low},
and mobile applications~\cite{gordon2015accelerating}. We extends the redundancy
and offer a variety of policies for combining results from multiple services.

\section{Profiling with Efficiency}
\label{sec:prof-with-effic}

\para{Bayesian Optimization.} To optimize complex systems in a principled way,
many frameworks employ Bayesian Optimizations to tune application behavior, such
as CherryPick~\cite{alipourfard2017cherrypick}, FLASH~\cite{zhang2016flash}, and
BOAT~\cite{dalibard2017boat}. These frameworks focus on single-objective
optimization: minimizing job completion time or maximizing application
accuracy. In contrast, \sysname{} addresses a multi-dimensional optimization
between application accuracy and processing times. We demonstrated that BO
outperforms greedy heuristic approach used in VideoStorm~\cite{zhang2017live}.

\section{Related Systems}
\label{sec:related-systems}

\para{Stream Processing Systems.} Early streaming
databases~\cite{abadi2005design, chandrasekaran2003telegraphcq} have explored
the use of dataflow models with specialized operators for stream
processing. Recent research projects and open-source
systems~\cite{akidau2013millwheel, toshniwal2014storm, sanjeev2015twitter,
  zaharia2013discretized, carbone2015apache} primarily focus on fault-tolerance
in the context of a single cluster. When facing back pressure,
Storm~\cite{toshniwal2014storm}, Spark Streaming~\cite{zaharia2013discretized}
and Heron~\cite{sanjeev2015twitter} throttle data ingestion; Apache
Flink~\cite{carbone2015apache} uses edge-by-edge back-pressure techniques
similar to TCP flow control; Faucet~\cite{lattuada2016faucet} leaves the flow
control logic up to developers.  While our work has a large debt to prior
streaming work, \sysname{} targets at the wide area and explicitly explores the
trade-off between data fidelity and freshness.

\para{Model Serving.} Frameworks such as Clipper~\cite{crankshaw2017clipper} and
TensorFlow Serving~\cite{tensorflow2017serving} only focus on system-level
techniques such as batching and hardware acceleration to improve
throughput. While Clipper allows ensemble of models, the purpose is to improve
accuracy at the cost of resources. Both frameworks have poor performance when
under overload.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
