\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Introduction}

Over the past two decades, we have seen a growing number of networked sensors
and actuators installed in our connected world. These sensors and actuators
offer an unprecedented ability to monitor and act. Because of the enormous
potentials in solving societal-scale problems, this trend has gained significant
attraction, as demonstrated by its many names: Internet of Things
(IoT)~\cite{atzori2010internet}, Internet of Everything
(IoE)~\cite{bradley2013internet}, Industry 4.0~\cite{lasi2014industry}, The
Industrial Internet~\cite{eigner2018industrial}, TSensors (Trillion
Sensors)~\cite{bogue2014towards}, Machine to Machine
(M2M)~\cite{anton2014machine}, Smarter Planet~\cite{palmisano2008smarter},
etc. In this thesis, we use the term ``swarm''---as called by Jan Rabaey in a
keynote talk at ASPDAC 2008~\cite{rabaey2008brand}---to refer to the vast
collection of networked sensors and actuators.

Swarm applications generate, transport, distill, and process large streams of
data across the wide area in real time. For example, large cities such as London
and Beijing have deployed millions of cameras for surveillance and traffic
control~\cite{skynet, london.surveillance}. Buildings are increasingly equipped
with a wide variety of sensors to improve energy efficiency and occupant
comfort~\cite{dawson2010smap, krioukov2012building}.

Riding on the popularity of the cloud infrastructure, swarm application
developers have adopted the cloud as a universal computation resource and a
storage backend~\cite{carriots, grovestreams, sami, xively, gupta2014bolt,
  zachariah1001internet}. This trend is understandable given the economic
benefits and simplified management.

Privacy, Security, Availability, Latency, Bandwidth, etc. However, due to
fundamental differences and unique characteristics of swarm applications, it is
not the best long-term approach. Large data: Swarm systems rely on vast numbers
of sensors that are generating massive amounts of data. Swarms and swarmlets
that dynamically recruit resources will compete for those resources.

To compensate the cloud, new infrastructure focusing edge computing appear, such
as fog~\cite{bonomi2012fog, bar2013fog}, cloudlet~\cite{ha2014towards,
  satyanarayanan2009case, chen2018application}, and Swarmbox. While reducing the
distance, these further increase the heterogeneous landscape: swarm components
are of various types, requiring interfacing and interoperability across multiple
platforms and models of computation.

We recognize the challenges in developing swarm applications: constrained
resource and heterogeneous environment. We argue that the key to unfold the
potential of swarm applications is to allow applications to adapt to environment
changes. Manual adaptation or exhaustive explore the design space are not
feasible given the scale and large problem space.

In this thesis, we propose to provide adaptation as a core abstraction in
application development. In this way, we can build tools to automatically learn
the effect of adaptation and apply adaptation strategies accordingly. We
demonstrate this methodology with two systems focusing on network resources and
compute resources for swarm applications.

\vspace{1em}

\noindent\textbf{Thesis Statement}: \textit{Providing adaptation as a programming
  abstraction allows for resilient swarm applications with less developer
  effort.}

\vspace{1em}

\section{Challenges with Developing Swarm Applications}
\label{sec:chall-with-exist}

We identify the following challenges that are unique to swarm applications:

\para{Limited Resource.} Swarm systems rely on vast numbers of heterogeneous
sensors that are generating massive amounts of data.

\para{Ad-hoc Development.} Developers strive to make the application working due
to many moving pieces.

\para{Huge Design Space.} Many devices. Choices of sensors, algorithms, data
quality.

\para{Heterogeneous Platforms.} Ranging from cheap low power platforms to
powerful workstation.

These challenges are hard to overcome.

\section{Adaptation as a First-class Citizen}
\label{sec:adaptation}

\para{API.} To encode adaption and allow tools to be built in a systematic way.
Such API can be reused both for development and for execution: with a effective
runtime.

\para{Automatic Profiling and Optimization.} Free developer from manual tuning
knobs or struggle to explore a huge parameter space.

Take network resource as an example, when facing situations where the bandwidth
is not sufficient, applications deployed today either choose a conservative
setting (e.g.\,only delivering 360p videos) or leave their fate to the
underlying transport layer: (1) in the case of TCP, the sender will be blocked
and data are backlogged, leading to severe delay; (2) in the case of UDP,
uncontrolled packet loss occurs, leading to application performance
drop. Instead of ``suffering'' from a degraded network, applications can act
proactively by adjusting their behavior: reducing the data rate to ensure that
important data are delivered in time.

This network-adaptation profile remains the same across devices.

When we apply the same principle to compute resource, in Chapter 3, we focus on
performance modeling and improve the efficiency. Unique challenges:

\section{Summary of Results}
\label{sec:summary-results-1}

\begin{enumerate}
\item We propose to introduces new programming abstractions by which a developer
  expresses \emph{what} adaptations are available. Importantly, developers do
  not have to specify exactly when and how different adaptations are to be used
  which is instead left to the underlying framework.

\item Rather than rely on manual policies, we can build tools that automatically
  \emph{learns} adaptation policy that are Pareto optimal. This learning process
  can be both offline and online, exploiting parallelism, sampling or
  statistical approaches to efficiently explore the configuration space.

\item We also demonstrate how such strategy can be employed in running systems
  and adapt to resource changes. For example, \sysname{} matches the streaming
  data rate to the measured available bandwidth. Upon encountering network
  congestion, it increases the degradation level to reduce the data rate, such
  that no persistent queue builds up. To recover, it progressively decreases the
  degradation level after probing for more available bandwidth. Our experiments
  show that \sysname{} achieves sub-second latency with only nominal accuracy
  drop (2-6\%).
\end{enumerate}

\section{Thesis Organization}
\label{sec:thesis-organization}

The remainder of this thesis is organized as follows:

\begin{itemize}
\item In Chapter 2, I first describe the landscape development for swarm
  applications. This overview, discussion is based on joint work with Nitesh
  Mor, John Kolb, Douglas S. Chan, Nikhil Goyal Ken Lutz, Eric Allman, John
  Wawrzynek, Edward A. Lee, John Kubiatowicz, Shuhei Emoto and Edward
  A. Lee~\cite{zhang2015cloud}.
\item In Chapter 3, I present the adaptation on network resources. The chapter
  is based on joint work with Xin Jin, Sylvia Ratnasamy, John Wawrzynek, and
  Edward A. Lee~\cite{zhang2018awstream}.
\item In Chapter 4, I present the adaptation on compute resources. The chapter
  is based on joint work with Xin Jin, and Edward A. Lee.
\item Chapter 5 discusses related research and industrial efforts related to
  adaptation.
\item Finally, I conclude this thesis and identify important research directions
  for future work.
\end{itemize}

The research presented in this thesis is supported in part by Berkeley
Ubiquitous SwarmLab~\cite{swarmlab} the TerraSwarm Research
Center~\cite{terraswarm}, one of six centers supported by the STARnet phase of
the Focus Center Research Program (FCRP) a Semiconductor Research Corporation
program sponsored by MARCO and DARPA.



\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
